{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 0. Select Analysis\n",
    "\n",
    "We have a user input here that can be modified to be either 'within' or 'across'. As you know the research design includes four time points T1 to T4 where T1 and T2 are pre and post intervention on the first session and T3 and T4 are pre and post intervention on the final session. \n",
    "\n",
    "Our 'within' analysis investigates whether there are any immediate effects of the intervention and thus compares the pre and post of the first session (T1 vs T2). Within refers to the analysis of data within a session.\n",
    "\n",
    "Our 'across' analysis investigates whether there are any long-term effects of the intervention by comparing the first session to the final session (focusing on pre-intervention: T1 vs T3). Across refers to the analysis of data across sessions.\n",
    "\n",
    "The remainder of this notebook will depend on this input, so to see each result would be to run the remainder twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hypothesis = 2 #Can be 1 (t1 vs t2) or 2 (t1 vs T3)\n",
    "\n",
    "if hypothesis == 1:\n",
    "    fileName = 'autoRAFeaturesDataT1vsT2.csv'\n",
    "elif hypothesis == 2:\n",
    "    fileName = 'autoRAFeaturesDataT1vsT3.csv'\n",
    "else:\n",
    "    print('Analysis not supported. Please use hypothesis = 1 or hypothesis = 2.')\n",
    "    \n",
    "print(fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Setup Environment and Load Data\n",
    "\n",
    "We will begin by setting up our environment and loading our features dataset from the last script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.1. Import Modules\n",
    "\n",
    "First, we must import the modules we will use in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from autora.skl.darts import DARTSRegressor, ValueType, DARTSExecutionMonitor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.2. Load Data\n",
    "We will here load in the data of EEG features, we created in the last script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95, 3)\n"
     ]
    }
   ],
   "source": [
    "featuresData = np.genfromtxt(fileName, delimiter=',')\n",
    "\n",
    "print(featuresData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.3. Split Data Into Predictors and Outcomes\n",
    "\n",
    "Although not a necessary step, I like to split my predictors from my outcomes explicitly for easier readability. We will use the first column as out outcomes, and the remaining columns as our predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outcomes = featuresData[:,0]\n",
    "predictors = featuresData[:,1:]\n",
    "\n",
    "print(outcomes.shape)\n",
    "print(predictors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.4 Normalize Predictors\n",
    "\n",
    "Before we feed our data to the autonomous research assistant, we also need to normalize our predictors. Note that the predictors are *very* small. Without proper initialization or data normalization, machine learning algorithms have difficulty learning from the data because patterns more difficult to the detect (e.g. for small values). For this reason, we seek to normalize our predictors such that they have a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Mean: 0.01255089096521041\n",
      "Old Standard Deviation: 0.14068570308882608\n",
      "New Mean: 0.01255089096521041\n",
      "New Standard Deviation: 0.14068570308882608\n"
     ]
    }
   ],
   "source": [
    "# normalize predictors\n",
    "print(\"Old Mean: \" + str(np.mean(predictors)))\n",
    "print(\"Old Standard Deviation: \" + str(np.std(predictors)))\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#predictors = scaler.fit_transform(predictors)\n",
    "\n",
    "print(\"New Mean: \" + str(np.mean(predictors)))\n",
    "print(\"New Standard Deviation: \" + str(np.std(predictors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.1. Split Data Into Train and Test\n",
    "\n",
    "Machine learning relies on a train and test set and here we are going to use train_test_split from the scikit learn module to split data in this way. By default, this function uses 25% of the data as a test set, but this may be adjusted if preferred. Note that we are setting a seed (random_state = 1251) for reproducibility within the workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71, 2)\n",
      "(24, 2)\n",
      "(71,)\n",
      "(24,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(predictors, outcomes, random_state = 1251)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note that we use upper case X to denote the predictors and lower case y to denote the outcomes. This is because X is a matrix (with rows corresponding to observations and columns corresponding to predictors) and y is a vector (with rows corresponding to observations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Differentiable Architecture Search (DARTS)\n",
    "\n",
    "Now that we have our predictors and outcomes, we can use the autonomous research assistant to identify an interpretable model that can predict the outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## How it Works (you may skip this section)\n",
    "\n",
    "Regular DARTS treats the architecture of a neural network as a directed acyclic computation graph (DAG), containing $N$ nodes in sequential order.\n",
    "\n",
    "<img src=\"computation_graph.jpg\" alt=\"Illustration of a Computation Graph\" width=\"1000\"></img>\n",
    "\n",
    "Each node $x_i$ corresponds to a latent representation of the input space. Each directed edge $e_{i, j}$ is associated with some operation  $o_{i,j}$ that transforms the representation of the preceding node $i$, and feeds it to node $j$. Each intermediate node is computed by integrating over its transformed predecessors:\n",
    "\n",
    "$x_j = \\sum_{i<j} o_{i,j} \\left( x_{i} \\right).$\n",
    "\n",
    "Every output node is computed by linearly combining all intermediate nodes projecting to it. The goal of DARTS is to identify all operations $o_{i,j}$ of the DAG. Following Liu et al. (2019), we define {$\\mathscr{O} = \\{o^1_{i,j}, o^2_{i,j}, \\dots, o^M_{i,j}\\}$} to be the set of $M$ candidate operations associated with edge $e_{i, j}$ where every operation $o^m_{i,j}(x_i)$ corresponds to some function applied to $x_{i}$ (e.g. linear,  exponential or logistic). DARTS relaxes the problem of searching over candidate operations by formulating the transformation associated with an edge as a mixture of all possible operations in $\\mathscr{O}$ (cf. Figure A-B):\n",
    "\n",
    "$\\bar{o}_{i,j}(x) = \\sum_{o \\in \\mathscr{O}} \\frac{\\textrm{exp}({\\alpha^o_{i,j}})}{\\sum_{o' \\in \\mathscr{O}} \\textrm{exp}({\\alpha^{o'}_{i,j}})} \\cdot o_{i,j}(x).$\n",
    "\n",
    "where each operation is weighted by the softmax transformation of its architectural weight $\\alpha^o_{i,j}$. Every edge $e_{i, j}$ is assigned a weight vector $\\alpha_{i,j}$ of dimension $M$, containing the weights of all possible candidate operations for that edge. The set of all architecture weight vectors $\\alpha = \\{\\alpha_{i,j}\\}$ determines the architecture of the model. Thus, searching the architecture amounts to identifying $\\alpha$. The key contribution of DARTS is that searching $\\alpha$ becomes amenable to gradient descent after relaxing the search space to become continuous. However, minimizing the loss function of the model $\\mathscr{L}(w,\\alpha)$ requires finding both $\\alpha^*$ and $w^*$---the parameters of the computation graph.\\footnote{This includes the parameters of each candidate operation $o^m_{i,j}$.} Liu et al. (2019) propose to learn $\\alpha$ and $w$ simultaneously using bi-level optimization:<br><br>\n",
    "\n",
    "$\\min_\\alpha \\mathscr{L}_{\\textrm{val}}\\left(w^*(\\alpha),\\alpha\\right) \\\\\n",
    "\\textrm{s.t. } w^*(\\alpha) = \\underset{w}{\\operatorname{argmin}}   \\mathscr{L}_{\\textrm{train}}(w, \\alpha).$\n",
    "\n",
    "That is, one can obtain $\\alpha^*$ through gradient descent, by iterating through the following steps:\n",
    "\n",
    "\n",
    "- Obtain the optimal set of weights $w^*$ for the current architecture $\\alpha$ by minimizing the training loss $\\mathscr{L}_{\\textrm{train}}(w, \\alpha)$.\n",
    "- Update the architecture $\\alpha$ (cf. Figure C) by following the gradient of the validation loss $\\nabla  \\mathscr{L}_{\\textrm{val}}\\left(w^*,\\alpha\\right)$.\n",
    "\n",
    "\n",
    "Once $\\alpha^*$ is found, one can obtain the final architecture by replacing $\\bar{o}_{i,j}$ with the operation that has the highest architectural weight, i.e. $o_{i,j}\\leftarrow \\textrm{argmax}_o \\alpha^{*o}_{i,j}$ (Figure D)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Defining the Search Space\n",
    "\n",
    "DARTS is a machine learning algorithm that uses a search space of operations to find the best model. The search space is defined by the set of operations that can be applied in each computation step of the model. These operations are also referred to as *primitives*. We can select from the following space of primitives:\n",
    "\n",
    "- **zero**: The output of the computation $x_j$ is not dependent on its input $x_i$.\n",
    "- **add**: The output of the computation $x_j$ amounts to its input $x_i$.\n",
    "- **subtract**: The output of the computation $x_j$ amounts to $-x_i$.\n",
    "- **mult**: The output of the computation $x_j$ is its input $x_i$ multiplied by some constant $a$.\n",
    "- **linear**: The output of the computation $x_j$ is linearly dependent on its input $x_i$: $x_j = a * x_i + b$.\n",
    "- **relu**: The output of the computation $x_j$ is a rectified linear function of its input $x_i$: $x_j = \\max(0, x_i)$.\n",
    "- **exp**: The output of the computation $x_j$ is exponentially dependent on its input $x_i$: $x_j = exp(x_i)$.\n",
    "- **logistic**: The output of the computation $x_j$ is a logistic function of its input $x_i$: $x_j = \\frac{1}{1 + \\exp(-b * x_i)}$.\n",
    "- **sin**: The output of the computation $x_j$ is the sinus function of its input $x_i$: $x_j = sin(x_i)$.\n",
    "- **cos**: The output of the computation $x_j$ is the cosinus function of its input $x_i$: $x_j = cos(x_i)$.\n",
    "- **tanh**: The output of the computation $x_j$ is the tangens hyperbolicus of its input $x_i$: $x_j = tanh(x_i)$.\n",
    "\n",
    "Some of the primitives above may also be preceded by a linear transformation, allowing for more degrees of freedom in the search space:\n",
    "\n",
    "- **linear_relu**: The output of the computation $x_j$ is a rectified linear function of its *linearly transformed* input $x_i$: $x_j = \\max(0, (a * x_i + b)$.\n",
    "- **linear_exp**: The output of the computation $x_j$ is exponentially dependent on its *linearly transformed* input $x_i$: $x_j = \\exp(a * x_i + b)$.\n",
    "- **linear_logistic**: The output of the computation $x_j$ is a logistic function of its *linearly transformed* input $x_i$: $x_j = \\frac{1}{1 + \\exp(-b * (a * x_i + b))}$.\n",
    "- **linear_sin**: The output of the computation $x_j$ the sinus function of its *linearly transformed* input $x_i$: $x_j = a * \\sin(a * x_i + b)$.\n",
    "- **linear_cos**: The output of the computation $x_j$ the cosinus function of its *linearly transformed* input $x_i$: $x_j = a * \\cos(a * x_i + b)$.\n",
    "- **linear_tanh**: The output of the computation $x_j$ the tangens hyperbolicus of its *linearly transformed* input $x_i$: $x_j = a * \\tanh(a * x_i + b)$.\n",
    "\n",
    "\n",
    "Let's begin with the following primitives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PRIMITIVES = [\n",
    "    \"none\",\n",
    "    \"add\",\n",
    "    \"subtract\",\n",
    "    \"logistic\",\n",
    "    \"exp\",\n",
    "    \"relu\",\n",
    "    \"cos\",\n",
    "    \"sin\",\n",
    "    \"tanh\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Set up the DARTS Regresssor\n",
    "\n",
    "We will use the DARTS Regresssor to predict the outcomes. Meta-parameters are used to control the search space and the search algorithm. DARTS has quite a lot of those parameters. This section provides a basic overview of all parameters along with a description of their effects.\n",
    "\n",
    "### General DARTS meta-parameters\n",
    "\n",
    "- **`num_graph_nodes`**: The number of latent variables used to represent the model.\n",
    "- **`max_epochs`**: The maximum number of epochs to run DARTS. This corresponds to the total number of architecture updates. These updates affect the architecture weights $\\alpha$ indicating the relative contribution of each operation for a given computation step.\n",
    "- **`output_type`**: The type of output to produce. We can choose between the following output types:\n",
    "    - `ValueType.REAL` (default): The output is a real number.\n",
    "    - `ValueType.PROBABILITY`: The output is a probability.\n",
    "    - `ValueType.CLASS`: The output is a probability distribution over classes.\n",
    "\n",
    "    In our case, we treat the outcome as a probability (e.g., the probability that the data comes from the first session T1 versus second session T2), so we will use **`ValueType.PROBABILITY`**.\n",
    "\n",
    "### Meta-parameters for the architecture updates\n",
    "The following parameters affect the updating of the architecture weights $\\alpha$:\n",
    "\n",
    "- **`arch_learning_rate_max`**: The initial (maximum) learning rate for updating the architecture updates. The higher the learning rate, the larger the steps taken to update the architecture weights. The learning rate decays with each epoch.\n",
    "- **`arch_weight_decay`**: The weight decay for the architecture weights. The higher the weight decay, the more the high architecture weights are pressured to be small.\n",
    "- **`arch_weight_decay_df`**: An additional weight decay that scales with the number of parameters (degrees of freedom) per operation. The higher this weight decay, the more DARTS will favor operations with few parameters.\n",
    "\n",
    "### Meta-parameters for the parameter updates\n",
    "The following parameters affect the updating of the parameters associated with each operation:\n",
    "\n",
    "- **`param_updates_per_epoch`**: The number of steps taken by the parameter optimizer per epoch. Once the architecture updates are complete, the parameters associated with each operation are updated by a stochastic gradient descent over this number of steps.\n",
    "- **`param_learning_rate_max`**: The initial (maximum) learning rate for updating the parameters. The higher the learning rate, the larger the steps taken to update the parameters. Note that the learning rate is scheduled to converge over the total number of parameter updates to **`learning_rate_min`**.\n",
    "- **`param_learning_rate_min`**: The smallest possible learning rate for updating the parameters.\n",
    "- **`param_momentum`**: The momentum for the architecture updates. The higher the momentum, the more the steps taken to update the architecture weights will be influenced by previous steps.\n",
    "- **`param_weight_decay`**: The weight decay for the parameters. The higher the weight decay, the more the high parameters of each operation are pressured to be small.\n",
    "\n",
    "### Meta-parameters for the classifier\n",
    "The final output of the DARTS model is computed by concatenating all edges in the computation graph into a single vector and then adding a linear classifier. The linear classifier can attach a coefficient to each edge (weighing the contribution of that edge to the final output), and it can add a constant bias term. The following parameters affect the behavior of the classifier:\n",
    "\n",
    "- **`train_classifier_coefficients`**: If set to `True`, the classifier coefficient of each edge will be trained (otherwise each coefficient is set to `1`, reflecting an equal contribution of each edge to the final output).\n",
    "- **`train_classifier_bias`**: If set to `True`, the bias term of the classifier will be trained (otherwise the bias term is set to `0`).\n",
    "\n",
    "\n",
    "\n",
    "Let's set up the DARTS regressor with some default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "darts_estimator = DARTSRegressor(\n",
    "        num_graph_nodes=1,\n",
    "        param_updates_per_epoch=100,\n",
    "        max_epochs=300,\n",
    "        arch_updates_per_epoch=1,\n",
    "        param_weight_decay=3e-4,\n",
    "        arch_weight_decay_df=0.001,\n",
    "        arch_weight_decay=1e-4,\n",
    "        arch_learning_rate_max=0.3,\n",
    "        param_learning_rate_max=0.0025,\n",
    "        param_learning_rate_min=0.01,\n",
    "        param_momentum=0.90,\n",
    "        primitives=PRIMITIVES,\n",
    "        train_classifier_bias=False,\n",
    "        train_classifier_coefficients=False,\n",
    "        output_type = ValueType.PROBABILITY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Run the DARTS Regressor\n",
    "\n",
    "Now we have everything to run differentiable architecture search (see Figure C). There are three steps to running DARTS:\n",
    "\n",
    "1. Run the architecture search by fitting the mixture model.\n",
    "\n",
    "2. Sample the final architecture weights and re-train the parameters of the model under the sampled architecture. In this case, we will sample each edge according to the *highest architecture weight*.\n",
    "\n",
    "3. Print and visualize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.029796123504638672,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 300,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7a707c59bc486b90f2a592a485e207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\n",
      "k1 = + x1 - x2\n",
      "y1 = 1.00 * k1 + 0.0\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 5.0.1 (20220821.0811)\n -->\n<!-- Pages: 1 -->\n<svg width=\"518pt\" height=\"98pt\"\n viewBox=\"0.00 0.00 518.00 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-94 514,-94 514,4 -4,4\"/>\n<!-- x1 -->\n<g id=\"node1\" class=\"node\">\n<title>x1</title>\n<polygon fill=\"#f1edb9\" stroke=\"black\" stroke-width=\"2\" points=\"36,-90 0,-90 0,-54 36,-54 36,-90\"/>\n<text text-anchor=\"middle\" x=\"18\" y=\"-67\" font-family=\"times\" font-size=\"20.00\">x1</text>\n</g>\n<!-- k1 -->\n<g id=\"node3\" class=\"node\">\n<title>k1</title>\n<polygon fill=\"#bbccf9\" stroke=\"black\" stroke-width=\"2\" points=\"135,-63 99,-63 99,-27 135,-27 135,-63\"/>\n<text text-anchor=\"middle\" x=\"117\" y=\"-40\" font-family=\"times\" font-size=\"20.00\">k1</text>\n</g>\n<!-- x1&#45;&gt;k1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>x1&#45;&gt;k1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M36.34,-67.17C50.96,-63.1 72.14,-57.21 88.98,-52.52\"/>\n<polygon fill=\"gray\" stroke=\"black\" points=\"90.11,-55.84 98.81,-49.79 88.24,-49.1 90.11,-55.84\"/>\n<text text-anchor=\"middle\" x=\"67.5\" y=\"-67\" font-family=\"times\" font-size=\"20.00\">+ x</text>\n</g>\n<!-- x2 -->\n<g id=\"node2\" class=\"node\">\n<title>x2</title>\n<polygon fill=\"#f1edb9\" stroke=\"black\" stroke-width=\"2\" points=\"36,-36 0,-36 0,0 36,0 36,-36\"/>\n<text text-anchor=\"middle\" x=\"18\" y=\"-13\" font-family=\"times\" font-size=\"20.00\">x2</text>\n</g>\n<!-- x2&#45;&gt;k1 -->\n<g id=\"edge2\" class=\"edge\">\n<title>x2&#45;&gt;k1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M36.12,-19.85C48.72,-21.5 66.18,-24.38 81,-29 83.81,-29.88 86.69,-30.92 89.53,-32.06\"/>\n<polygon fill=\"gray\" stroke=\"black\" points=\"88.33,-35.35 98.89,-36.13 91.12,-28.93 88.33,-35.35\"/>\n<text text-anchor=\"middle\" x=\"67.5\" y=\"-35\" font-family=\"times\" font-size=\"20.00\">&#45; x</text>\n</g>\n<!-- P(detected) = Sigmoid(x + 0.00) -->\n<g id=\"node4\" class=\"node\">\n<title>P(detected) = Sigmoid(x + 0.00)</title>\n<polygon fill=\"#cbe7c7\" stroke=\"black\" stroke-width=\"2\" points=\"510,-63 236,-63 236,-27 510,-27 510,-63\"/>\n<text text-anchor=\"middle\" x=\"373\" y=\"-40\" font-family=\"times\" font-size=\"20.00\">P(detected) = Sigmoid(x + 0.00)</text>\n</g>\n<!-- k1&#45;&gt;P(detected) = Sigmoid(x + 0.00) -->\n<g id=\"edge3\" class=\"edge\">\n<title>k1&#45;&gt;P(detected) = Sigmoid(x + 0.00)</title>\n<path fill=\"none\" stroke=\"black\" d=\"M135.06,-45C154.73,-45 189.09,-45 225.64,-45\"/>\n<polygon fill=\"gray\" stroke=\"black\" points=\"225.99,-48.5 235.99,-45 225.99,-41.5 225.99,-48.5\"/>\n<text text-anchor=\"middle\" x=\"185.5\" y=\"-51\" font-family=\"times\" font-size=\"20.00\">1.00 * x</text>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7faded1ef970>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the architecture weights. By default, this will by default return the model with the highest architecture weights\n",
    "darts_estimator.fit(X_train, y_train)\n",
    "\n",
    "# re-fit the model with the fixed architecture weights\n",
    "darts_estimator.set_params(\n",
    "    max_epochs=0,  # no epochs of architecture fitting\n",
    "    param_updates_for_sampled_model=1000,  # 1000 steps of param optimiziation\n",
    ")\n",
    "# print the model's formula\n",
    "print(darts_estimator.model_repr())\n",
    "# visualize the model\n",
    "darts_estimator.visualize_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After running DARTS, we can also resample an architecture from the mixture model (see Figure D). If we select ``sampling_strategy=\"sample\"`` then we can sample each operation with a propability that is proportional to it's final architecture weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "darts_estimator.set_params(\n",
    "    max_epochs = 0, # make sure to not re-train architecture weights\n",
    "    sampling_strategy=\"sample\",  # overriding default \"max\"\n",
    "    param_updates_for_sampled_model=800,\n",
    ")\n",
    "darts_estimator.fit(X_train, y_train)\n",
    "print(darts_estimator.model_repr())\n",
    "darts_estimator.visualize_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To recover the initial model, we need to return the sampling strategy to the default `\"max\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018082618713378906,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 0,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b09c383e644876a7653c659c9ecd3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 5.0.1 (20220821.0811)\n -->\n<!-- Pages: 1 -->\n<svg width=\"518pt\" height=\"98pt\"\n viewBox=\"0.00 0.00 518.00 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-94 514,-94 514,4 -4,4\"/>\n<!-- x1 -->\n<g id=\"node1\" class=\"node\">\n<title>x1</title>\n<polygon fill=\"#f1edb9\" stroke=\"black\" stroke-width=\"2\" points=\"36,-90 0,-90 0,-54 36,-54 36,-90\"/>\n<text text-anchor=\"middle\" x=\"18\" y=\"-67\" font-family=\"times\" font-size=\"20.00\">x1</text>\n</g>\n<!-- k1 -->\n<g id=\"node3\" class=\"node\">\n<title>k1</title>\n<polygon fill=\"#bbccf9\" stroke=\"black\" stroke-width=\"2\" points=\"135,-63 99,-63 99,-27 135,-27 135,-63\"/>\n<text text-anchor=\"middle\" x=\"117\" y=\"-40\" font-family=\"times\" font-size=\"20.00\">k1</text>\n</g>\n<!-- x1&#45;&gt;k1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>x1&#45;&gt;k1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M36.34,-67.17C50.96,-63.1 72.14,-57.21 88.98,-52.52\"/>\n<polygon fill=\"gray\" stroke=\"black\" points=\"90.11,-55.84 98.81,-49.79 88.24,-49.1 90.11,-55.84\"/>\n<text text-anchor=\"middle\" x=\"67.5\" y=\"-67\" font-family=\"times\" font-size=\"20.00\">+ x</text>\n</g>\n<!-- x2 -->\n<g id=\"node2\" class=\"node\">\n<title>x2</title>\n<polygon fill=\"#f1edb9\" stroke=\"black\" stroke-width=\"2\" points=\"36,-36 0,-36 0,0 36,0 36,-36\"/>\n<text text-anchor=\"middle\" x=\"18\" y=\"-13\" font-family=\"times\" font-size=\"20.00\">x2</text>\n</g>\n<!-- x2&#45;&gt;k1 -->\n<g id=\"edge2\" class=\"edge\">\n<title>x2&#45;&gt;k1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M36.12,-19.85C48.72,-21.5 66.18,-24.38 81,-29 83.81,-29.88 86.69,-30.92 89.53,-32.06\"/>\n<polygon fill=\"gray\" stroke=\"black\" points=\"88.33,-35.35 98.89,-36.13 91.12,-28.93 88.33,-35.35\"/>\n<text text-anchor=\"middle\" x=\"67.5\" y=\"-35\" font-family=\"times\" font-size=\"20.00\">&#45; x</text>\n</g>\n<!-- P(detected) = Sigmoid(x + 0.00) -->\n<g id=\"node4\" class=\"node\">\n<title>P(detected) = Sigmoid(x + 0.00)</title>\n<polygon fill=\"#cbe7c7\" stroke=\"black\" stroke-width=\"2\" points=\"510,-63 236,-63 236,-27 510,-27 510,-63\"/>\n<text text-anchor=\"middle\" x=\"373\" y=\"-40\" font-family=\"times\" font-size=\"20.00\">P(detected) = Sigmoid(x + 0.00)</text>\n</g>\n<!-- k1&#45;&gt;P(detected) = Sigmoid(x + 0.00) -->\n<g id=\"edge3\" class=\"edge\">\n<title>k1&#45;&gt;P(detected) = Sigmoid(x + 0.00)</title>\n<path fill=\"none\" stroke=\"black\" d=\"M135.06,-45C154.73,-45 189.09,-45 225.64,-45\"/>\n<polygon fill=\"gray\" stroke=\"black\" points=\"225.99,-48.5 235.99,-45 225.99,-41.5 225.99,-48.5\"/>\n<text text-anchor=\"middle\" x=\"185.5\" y=\"-51\" font-family=\"times\" font-size=\"20.00\">1.00 * x</text>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7faded1ef070>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "darts_estimator.set_params(\n",
    "    max_epochs = 0, # make sure to not re-train architecture weights\n",
    "    sampling_strategy=\"max\",\n",
    "    param_updates_for_sampled_model=1000,\n",
    ")\n",
    "darts_estimator.fit(X_train, y_train)\n",
    "darts_estimator.visualize_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Diagnosing DARTS: The execution monitor.\n",
    "\n",
    "As you can see, there are lots of meta-parameters to choose from. To better understand what these parameters do, we want to have some more insight into the training dynamics of DARTS. We can obtain such insights from a so-called *execution monitor*. The monitor will provide us with two plots:\n",
    "\n",
    "1) **Training Curve**: We this plots the loss of the DARTS algorithm as a function of training epochs. The lower the loss, the better the algorithm performs. Using this plot, you can evaluate how well DARTS converges on the training data.\n",
    "\n",
    "2) **Architecture Weights**: Each edge in the computation graph is associated with an architecture weight. The monitor will display, for each edge, the trajectory of the corresponding architecture weights--each representing a different operation/primitive. Using this plot, you can evaluate which operations are preferred by DARTS over the course of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# set up the execution monitor\n",
    "execution_monitor_0 = DARTSExecutionMonitor()\n",
    "\n",
    "# pass the monitor to the regressor\n",
    "darts_estimator = DARTSRegressor(\n",
    "        execution_monitor=execution_monitor_0.execution_monitor,\n",
    "        # you may pass additional DARTS meta-parameters here, for now we will go with the defaults\n",
    ")\n",
    "\n",
    "# run DARTS\n",
    "darts_estimator.fit(X_train, y_train)\n",
    "\n",
    "# display the execution monitor\n",
    "execution_monitor_0.display()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Evaluate the Model\n",
    "\n",
    "Finally, let us evaluate the sampled model by computing it's accuracy on the test set. In this case, we will round each estimate of the model $\\hat{y} \\in [0,1]$ to either 0 or 1, and compare against the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_predicted = darts_estimator.predict(X_test)\n",
    "accuracy = 1 - np.mean(np.abs(np.round(y_predicted.T)-y_test))\n",
    "\n",
    "print('Accuracy: {:.4f}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 1\n",
    "\n",
    "Let us first gain some basic intuitions about DARTS. This is, perhaps, best accomplished by applying DARTS to a very simple test case (a unit test). In this test case we seek to recover a very simple function from synthetic data:\n",
    "\n",
    "$$f(x) = e^x$$\n",
    "\n",
    "The script below will generate synthetic data and then train a DARTS regressor to recover the function. You may want to run this script multiple times using different combinations of meta-parameters and primitives to see how the accuracy changes. For convenience, we pasted the meta-parameters below. You may also consult the documentation of AutoRA for further information: <a href=\"https://autoresearch.github.io/autora/\">https://autoresearch.github.io/autora/</a>.\n",
    "\n",
    "### General DARTS meta-parameters\n",
    "\n",
    "- **`num_graph_nodes`**: The number of latent variables used to represent the model.\n",
    "- **`max_epochs`**: The maximum number of epochs to run DARTS. This corresponds to the total number of architecture updates. These updates affect the architecture weights $\\alpha$ indicating the relative contribution of each operation for a given computation step.\n",
    "- **`output_type`**: The type of output to produce. We can choose between the following output types:\n",
    "    - `ValueType.REAL` (default): The output is a real number.\n",
    "    - `ValueType.PROBABILITY`: The output is a probability.\n",
    "    - `ValueType.CLASS`: The output is a probability distribution over classes.\n",
    "\n",
    "    In our case, we treat the outcome as a probability (e.g., the probability that the data comes from the first session T1 versus second session T2), so we will use **`ValueType.PROBABILITY`**.\n",
    "\n",
    "### Meta-parameters for the architecture updates\n",
    "The following parameters affect the updating of the architecture weights $\\alpha$:\n",
    "\n",
    "- **`arch_learning_rate_max`**: The initial (maximum) learning rate for updating the architecture updates. The higher the learning rate, the larger the steps taken to update the architecture weights. The learning rate decays with each epoch.\n",
    "- **`arch_weight_decay`**: The weight decay for the architecture weights. The higher the weight decay, the more the high architecture weights are pressured to be small.\n",
    "- **`arch_weight_decay_df`**: An additional weight decay that scales with the number of parameters (degrees of freedom) per operation. The higher this weight decay, the more DARTS will favor operations with few parameters.\n",
    "\n",
    "### Meta-parameters for the parameter updates\n",
    "The following parameters affect the updating of the parameters associated with each operation:\n",
    "\n",
    "- **`param_updates_per_epoch`**: The number of steps taken by the parameter optimizer per epoch. Once the architecture updates are complete, the parameters associated with each operation are updated by a stochastic gradient descent over this number of steps.\n",
    "- **`param_learning_rate_max`**: The initial (maximum) learning rate for updating the parameters. The higher the learning rate, the larger the steps taken to update the parameters. Note that the learning rate is scheduled to converge over the total number of parameter updates to **`learning_rate_min`**.\n",
    "- **`param_learning_rate_min`**: The smallest possible learning rate for updating the parameters.\n",
    "- **`param_momentum`**: The momentum for the architecture updates. The higher the momentum, the more the steps taken to update the architecture weights will be influenced by previous steps.\n",
    "- **`param_weight_decay`**: The weight decay for the parameters. The higher the weight decay, the more the high parameters of each operation are pressured to be small.\n",
    "\n",
    "### Meta-parameters for the classifier\n",
    "The final output of the DARTS model is computed by concatenating all edges in the computation graph into a single vector and then adding a linear classifier. The linear classifier can attach a coefficient to each edge (weighing the contribution of that edge to the final output), and it can add a constant bias term. The following parameters affect the behavior of the classifier:\n",
    "\n",
    "- **`train_classifier_coefficients`**: If set to `True`, the classifier coefficient of each edge will be trained (otherwise each coefficient is set to `1`, reflecting an equal contribution of each edge to the final output).\n",
    "- **`train_classifier_bias`**: If set to `True`, the bias term of the classifier will be trained (otherwise the bias term is set to `0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# generate the synthetic data: y = exp(x)\n",
    "x = np.expand_dims(np.linspace(start=-1, stop=1, num=500), 1)\n",
    "y = np.exp(x)\n",
    "\n",
    "# define the primitives\n",
    "primitives = [\n",
    "    \"none\",\n",
    "    \"add\",\n",
    "    \"subtract\",\n",
    "    \"logistic\",\n",
    "    \"exp\",\n",
    "    \"relu\",\n",
    "    \"cos\",\n",
    "    \"sin\",\n",
    "    \"tanh\",\n",
    "]\n",
    "\n",
    "execution_monitor_0 = DARTSExecutionMonitor()\n",
    "\n",
    "# train a DARTS regressor to recover the function\n",
    "regressor = DARTSRegressor(\n",
    "    execution_monitor=execution_monitor_0.execution_monitor,\n",
    "    num_graph_nodes=1,\n",
    "    param_updates_per_epoch=100,\n",
    "    max_epochs=300,\n",
    "    arch_updates_per_epoch=1,\n",
    "    param_weight_decay=3e-4,\n",
    "    arch_weight_decay_df=0.7,\n",
    "    arch_weight_decay=1e-4,\n",
    "    arch_learning_rate_max=0.01,\n",
    "    param_learning_rate_max=0.0025,\n",
    "    param_learning_rate_min=0.01,\n",
    "    param_momentum=0.90,\n",
    "    primitives=primitives,\n",
    "    train_classifier_bias=False,\n",
    "    train_classifier_coefficients=False,\n",
    "    output_type=ValueType.REAL,\n",
    ")\n",
    "\n",
    "regressor.fit(x, y)\n",
    "execution_monitor_0.display()\n",
    "\n",
    "# resample the architecture parameters\n",
    "regressor.set_params(\n",
    "    sampling_strategy=\"max\",\n",
    "    param_updates_for_sampled_model=100,\n",
    ")\n",
    "regressor.fit(x, y)\n",
    "\n",
    "# plot the ground truth against the model's prediction\n",
    "y_predict = regressor.predict(x)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y, \"o\")\n",
    "plt.plot(x, y_predict, \"-\")\n",
    "plt.legend([\"grund truth\", \"model prediction\"], loc=0)\n",
    "plt.show()\n",
    "\n",
    "# print the model\n",
    "print(regressor.model_repr())\n",
    "\n",
    "# visualize the model\n",
    "regressor.visualize_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 2\n",
    "\n",
    "Now that you have gained some basic intuitions about DARTS, we encourage you to improve the accuracy of the symbolic model on the extracted EEG features by trying out different search parameters and modifying the search space.\n",
    "\n",
    "For convenience, we have provided the following code to run and evaluate the search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# You may modify the search space below to improve the accuracy of the model.\n",
    "# See section \"Defining the Search Space\" for more details.\n",
    "\n",
    "import random\n",
    "\n",
    "outcomes = featuresData[:,0]\n",
    "predictors = featuresData[:,1:]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, outcomes)\n",
    "\n",
    "PRIMITIVES = [\n",
    "    \"none\",\n",
    "    \"add\",\n",
    "    \"subtract\",\n",
    "    \"linear\",\n",
    "    \"linear_logistic\",\n",
    "    \"mult\",\n",
    "    \"linear_relu\",\n",
    "    \"relu\",\n",
    "    \"exp\",\n",
    "    \"logistic\",\n",
    "    \"sin\",\n",
    "    \"cos\",\n",
    "    \"tanh\",\n",
    "    \"linear_exp\",\n",
    "    \"linear_sin\",\n",
    "    \"linear_cos\",\n",
    "    \"linear_tanh\"\n",
    "]\n",
    "\n",
    "# You may modify the search parameters below to improve the accuracy of the model.\n",
    "\n",
    "# General DARTS meta-parameters\n",
    "num_graph_nodes = 2\n",
    "max_epochs = 10\n",
    "sampling_strategy = 'max' # 'max' or 'sample'\n",
    "\n",
    "# Meta-parameters for the architecture updates\n",
    "arch_updates_per_epoch=1\n",
    "arch_learning_rate_max = .1\n",
    "arch_weight_decay = .01\n",
    "arch_weight_decay_df = .0001\n",
    "\n",
    "# Meta-parameters for the parameter updates\n",
    "param_updates_per_epoch = 500\n",
    "param_learning_rate_max = 0.0025\n",
    "param_learning_rate_min = 0.01\n",
    "param_weight_decay = 3e-4\n",
    "param_momentum = 0.90\n",
    "param_updates_for_sampled_model = 1000\n",
    "\n",
    "# Meta-parameters for the classifier\n",
    "train_classifier_bias=True,\n",
    "train_classifier_coefficients=True\n",
    "\n",
    "# we will add this monitor to display the training performance\n",
    "execution_monitor_0 = DARTSExecutionMonitor()\n",
    "\n",
    "# run DARTS\n",
    "darts_estimator = DARTSRegressor(\n",
    "    execution_monitor = execution_monitor_0.execution_monitor,\n",
    "    num_graph_nodes = num_graph_nodes,\n",
    "    max_epochs = max_epochs,\n",
    "    arch_updates_per_epoch = arch_updates_per_epoch,\n",
    "    arch_learning_rate_max = arch_learning_rate_max,\n",
    "    arch_weight_decay = arch_weight_decay,\n",
    "    arch_weight_decay_df = arch_weight_decay_df,\n",
    "    param_updates_per_epoch = param_updates_per_epoch,\n",
    "    param_learning_rate_max = param_learning_rate_max,\n",
    "    param_learning_rate_min = param_learning_rate_min,\n",
    "    param_weight_decay = param_weight_decay,\n",
    "    param_momentum = param_momentum,\n",
    "    train_classifier_bias = train_classifier_bias,\n",
    "    train_classifier_coefficients = train_classifier_coefficients,\n",
    "    output_type=ValueType.PROBABILITY,\n",
    "    primitives=PRIMITIVES,\n",
    ")\n",
    "\n",
    "darts_estimator.fit(X_train, y_train)\n",
    "\n",
    "# display the execution monitor\n",
    "execution_monitor_0.display()\n",
    "plt.show()\n",
    "\n",
    "# re-fit using the final architecture\n",
    "darts_estimator.set_params(\n",
    "    max_epochs = 0, # make sure to not re-train the architecture weights\n",
    "    sampling_strategy = sampling_strategy,\n",
    "    param_updates_for_sampled_model = param_updates_for_sampled_model,\n",
    ")\n",
    "darts_estimator.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model\n",
    "y_predicted = darts_estimator.predict(X_test)\n",
    "accuracy = 1 - np.mean(np.abs(np.round(y_predicted.T)-y_test))\n",
    "\n",
    "# print accuracy and visualize model\n",
    "print('******************')\n",
    "print('Accuracy: {0}%'.format(accuracy*100))\n",
    "print('******************')\n",
    "print(darts_estimator.model_repr())\n",
    "darts_estimator.visualize_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# References\n",
    "\n",
    "Liu, H., Simonyan, K., & Yang, Y. (2018). Darts: Differentiable architecture search. In *International Conference on Learning Representations*. arXiv: https://arxiv.org/abs/1806.09055\n",
    "\n",
    "Musslick, S. (2021). Recovering quantitative models of human information processing with differentiable architecture search. In *Proceedings of the 43rd Annual Conference of the Cognitive Science Society* (pp. 348â€“354). Vienna, AT. arXiv: https://arxiv.org/abs/2103.13939"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('webScrapingEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b8a14f8b8efb0c3b75845d00dd06fa81689b5b4d608e142ab559b13d684ddcb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
