{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 0. User Input - Datset of Interest\n",
    "hypothesis = 2\n",
    "\n",
    "if hypothesis == 1:\n",
    "    fileName = 'williamsBrainstormChallenge_T1vsT2Features.csv'\n",
    "elif hypothesis == 2:\n",
    "    fileName = 'williamsBrainstormChallenge_T1vsT3Features.csv'\n",
    "else:\n",
    "    print('Analysis not supported. Please use hypothesis = 1 or hypothesis = 2.')\n",
    "    \n",
    "#Step 1. Load Modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from autora.skl.darts import DARTSRegressor, ValueType, DARTSExecutionMonitor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import copy\n",
    "from IPython.display import clear_output\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# Step 2. Load Data, Split Into Predictors and Outcomes, and Normalize Predictors\n",
    "#Load Data \n",
    "featuresData = np.genfromtxt(fileName, delimiter=',')\n",
    "scaler = StandardScaler()\n",
    "featuresData[:,1:] = scaler.fit_transform(featuresData[:,1:])\n",
    "\n",
    "#Split data into predictors and outcomes\n",
    "outcomes = featuresData[:,0]\n",
    "predictors = featuresData[:,1:]\n",
    "\n",
    "# Step 3. Iterate Through Data Using the Leave-One-Out Metho\n",
    "PRIMITIVES = [\n",
    "    \"none\",\n",
    "    \"linear\",\n",
    "    \"linear_logistic\",\n",
    "    \"linear_relu\",\n",
    "    \"linear_sin\",\n",
    "    \"linear_tanh\"\n",
    "    ]\n",
    "\n",
    "#The main loop searching for a DARTS architecture\n",
    "avgAccuracies =[]\n",
    "x=1\n",
    "for run in range(1000):\n",
    "    accuracies = []\n",
    "    print((x/1000)*100)\n",
    "    x+=1\n",
    "\n",
    "    # General DARTS meta-parameters\n",
    "    num_graph_nodes = 1\n",
    "    max_epochs = 300\n",
    "    sampling_strategy = 'max'\n",
    "\n",
    "    # Meta-parameters for the architecture updates\n",
    "    arch_updates_per_epoch = 1\n",
    "    arch_learning_rate_max = 0.01\n",
    "    arch_weight_decay = 3e-4\n",
    "    arch_weight_decay_df = 0.01\n",
    "\n",
    "    # Meta-parameters for the parameter updates\n",
    "    param_updates_per_epoch = 100\n",
    "    param_learning_rate_max = 0.025\n",
    "    param_learning_rate_min = 0.01\n",
    "    param_weight_decay = 3e-4\n",
    "    param_momentum = 0.90\n",
    "    param_updates_for_sampled_model = 1000\n",
    "\n",
    "    # Meta-parameters for the classifier\n",
    "    train_classifier_bias=True,\n",
    "    train_classifier_coefficients=True\n",
    "\n",
    "    # we will add this monitor to display the training performance\n",
    "    execution_monitor_0 = DARTSExecutionMonitor()\n",
    "\n",
    "    # run DARTS\n",
    "    darts_estimator = DARTSRegressor(\n",
    "        execution_monitor = execution_monitor_0.execution_monitor,\n",
    "        num_graph_nodes = num_graph_nodes,\n",
    "        max_epochs = max_epochs,\n",
    "        arch_updates_per_epoch = arch_updates_per_epoch,\n",
    "        arch_learning_rate_max = arch_learning_rate_max,\n",
    "        arch_weight_decay = arch_weight_decay,\n",
    "        arch_weight_decay_df = arch_weight_decay_df,\n",
    "        param_updates_per_epoch = param_updates_per_epoch,\n",
    "        param_learning_rate_max = param_learning_rate_max,\n",
    "        param_learning_rate_min = param_learning_rate_min,\n",
    "        param_weight_decay = param_weight_decay,\n",
    "        param_momentum = param_momentum,\n",
    "        train_classifier_bias = train_classifier_bias,\n",
    "        train_classifier_coefficients = train_classifier_coefficients,\n",
    "        output_type=ValueType.PROBABILITY,\n",
    "        primitives=PRIMITIVES,\n",
    "    )\n",
    "\n",
    "    #Fit DARTS\n",
    "    darts_estimator.fit(predictors, outcomes)\n",
    "\n",
    "    #Saving architecture\n",
    "    fixedArchitecture = copy.deepcopy(darts_estimator.network_)\n",
    "    fullArchitecture = copy.deepcopy(darts_estimator)\n",
    "\n",
    "    #Leave-one-out cross-validation methods to determine architecture accuracy\n",
    "    for participant in range(len(featuresData)):\n",
    "\n",
    "        #To be explicit (although techinically unecessary), we will force the same, fixed architecture\n",
    "        darts_estimator.network_ = fixedArchitecture\n",
    "\n",
    "        #Determine final DARTS Architecture \n",
    "        darts_estimator.set_params(\n",
    "            max_epochs = 0,\n",
    "            arch_updates_per_epoch = 0,\n",
    "            num_graph_nodes = 1,\n",
    "            param_learning_rate_max = 0.025,\n",
    "            arch_weight_decay_df = 0.01,\n",
    "            arch_learning_rate_max = 0.01\n",
    "        )\n",
    "\n",
    "        #Split current data\n",
    "        X_test = featuresData[participant,1:]\n",
    "        X_test = X_test.reshape(1, -1)\n",
    "        y_test = featuresData[participant,0]\n",
    "\n",
    "        X_train = featuresData[:,1:]\n",
    "        X_train = np.delete(X_train, participant, 0)\n",
    "        y_train = featuresData[:,0]\n",
    "        y_train = np.delete(y_train, participant)\n",
    "\n",
    "        #Fit the new coefficients \n",
    "        darts_estimator.fit(X_train, y_train)\n",
    "\n",
    "        #Evaluate the model\n",
    "        y_predicted = darts_estimator.predict(X_test)\n",
    "        accuracy = 1 - np.mean(np.abs(np.round(y_predicted.T)-y_test))\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "    #Print and track accuracy\n",
    "    clear_output(wait=True)\n",
    "    print(round(np.mean(accuracies)*100,2))\n",
    "    avgAccuracies.append(round(np.mean(accuracies)*100,2))\n",
    "\n",
    "    #Keep track of all accuracies computes\n",
    "    with open('williamsBrainstormChallenge_SearchArchitecture.txt', 'a') as f:\n",
    "        stringToWrite = str(round(np.mean(accuracies)*100,4)) + '\\n'\n",
    "        f.write(stringToWrite)\n",
    "\n",
    "    #Only accept architectures with 70% or better predictions\n",
    "    if np.mean(accuracies)*100 >= 70:\n",
    "        filename = 'williamsBrainstormChallenge_Architecture.pickle'\n",
    "        with open(filename, 'wb') as handle:\n",
    "            pickle.dump(fullArchitecture, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4. Display Architecture \n",
    "print(fullArchitecture.model_repr())\n",
    "fullArchitecture.visualize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5. Extract 3 samples to demonstrate changing coefficients\n",
    "sampledParticipants = [10, 20, 30]\n",
    "\n",
    "for participant in sampledParticipants:\n",
    "        #To be explicit (although techinically unecessary), we will force the same, fixed architecture\n",
    "        darts_estimator.network_ = fixedArchitecture\n",
    "\n",
    "        #Determine final DARTS Architecture \n",
    "        darts_estimator.set_params(\n",
    "            max_epochs = 0,\n",
    "            arch_updates_per_epoch = 0,\n",
    "            num_graph_nodes = 1,\n",
    "            param_learning_rate_max = .025,\n",
    "            arch_weight_decay_df = .01,\n",
    "            arch_learning_rate_max = .01\n",
    "        )\n",
    "\n",
    "        #Split current data\n",
    "        X_test = featuresData[participant,1:]\n",
    "        X_test = X_test.reshape(1, -1)\n",
    "        y_test = featuresData[participant,0]\n",
    "\n",
    "        X_train = featuresData[:,1:]\n",
    "        X_train = np.delete(X_train, participant, 0)\n",
    "        y_train = featuresData[:,0]\n",
    "        y_train = np.delete(y_train, participant)\n",
    "\n",
    "        #Fit the new coefficients \n",
    "        darts_estimator.fit(X_train, y_train)\n",
    "\n",
    "        print(darts_estimator.model_repr())\n",
    "        darts_estimator.visualize_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b8a14f8b8efb0c3b75845d00dd06fa81689b5b4d608e142ab559b13d684ddcb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
